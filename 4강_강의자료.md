<aside>

## 목차

</aside>

> 강의 시청 후 궁금한 것이 있다면 무엇이든 물어보세요!
> 
> 
> <aside>
> 
> </aside>
> 

## 1. 들어가기에 앞서

<aside>
💡

**지난 강의 한눈에 리마인드**

</aside>

1. **소프트웨어 아키텍처란?**
    - 코드 구성에 대한 큰 그림
    - **“팀이 공유하는, 잘 바꾸기 어려운 핵심 설계 결정”**이 곧 아키텍처
    - **중요 포인트** : 프로젝트마다 “쉽게 바꾸기 어려운 것”은 다름
        - ex) 결제 시스템 ➜ **데이터 정합성·트랜잭션**이 최우선
        - ex) SNS 피드 ➜ **확장성·지연 시간**이 최우선
2. **왜 지금, 아키텍처인가?**
    
    
    | **페인포인트** | **나쁜 구조** | **좋은 아키텍처** |
    | --- | --- | --- |
    | **개발 속도** | 기능 추가할수록 속도 ↓ | 변경 비용 최소화, 속도 ↑ |
    | **버그 수정** | 어디서 터졌는지 추적 난이도 ↑ | 영향 범위 국소화, MTTR ↓ |
    | **팀 온보딩** | 새 멤버가 코드 숲에서 길 잃음 | 공통 이해(Shared Mental Model) ↑ |
    | **기술 교체** | DB·메시지 브로커 변경 시 대공사 | 외부 → 내부 의존 역전으로 교체 비용 ↓ |
3.  **아키텍처 설계 원칙과 기본기 (SOLID, TDD의 영향)**
    
    <aside>
    💡
    
    SOLID - 객체지향 5대원칙
    
    → “**변경에 강한 구조**”를 만들기 위한 가장 기초적인 레일
    
    </aside>
    
    - **SRP(단일 책임)** : 클래스/모듈은 *한 가지 일*만
    - **OCP(개방-폐쇄)** : 확장에는 **열려**, 변경에는 **닫혀**
    - **LSP(리스코프 치환)** : 하위 타입은 상위 타입을 대체 가능해야
    - **ISP(인터페이스 분리)** : 고객별 *작은 인터페이스* 지향
    - **DIP(의존성 역전)** : 추상(인터페이스)에 의존, 구체 구현 분리
    
    <aside>
    💡
    
    테스트하기 쉽다 = 구조가 좋다
    
    →  TDD 한 사이클만 돌려도 **SOLID 원칙이 자연 주입**됨
    
    </aside>
    
    | **TDD 단계** | **설계 신호** | **자동 도입되는 원칙** |
    | --- | --- | --- |
    | **Red** | “테스트 격리 필요” | **DIP**, 인터페이스 추출 |
    | **Green** | “가짜 객체로 통과” | **DI**, **SRP** |
    | **Refactor** | “확장성 확보” | **OCP**, **LSP**, **ISP** |
4. **아키텍처 패턴 비교 (Layered vs Hexagonal vs Clean)**
    
    
    |  | **Layered** | **Hexagonal** | **Clean** |
    | --- | --- | --- | --- |
    | **중심 철학** | 상-하 **한 방향** 의존 | 도메인 중심 **Port/Adapter** | **의존성 규칙** (안→밖 모름) |
    | **강점** | 단순·진입장벽 ↓ | 도메인 순수, 다채널 확장 ↑ | 변경 내성 최강, 테스트 ↑ |
    | **단점** | DB·UI와 결합 ↑ | 구조·추상화 복잡 | 학습 곡선 ↑, 초기 비용 ↑ |
    | **주 사용처** | 전통 CRUD 웹앱 | DDD, 멀티 UI/DB | 대규모·장수 프로젝트 |
5. 실무 적용 로드맵
    - MVP 단계 : 전통 Layered 패턴으로 빠른 출시
    - 복잡도 상승 신호 (다채널, 규칙 ↑, DB 교체)
        - 핵심 도메인 모듈부터 포팅
    - 장기 유지·대규모 팀 : 전사 공통 Clean Architecture 표준 정립
6. **실무형 인터뷰 질문  (각자 답변을 생각해보고 학습해보세요~!)**
    - **“소프트웨어 아키텍처를 한 문장으로 설명해 보세요.”**
    - “REST API·Batch Job·MQ 소비자 세 채널이 동일한 도메인 유스케이스(주문 확정)를 호출해야 합니다. 헥사고날/클린 관점에서 구조를 그려 주세요.”

## 2. 이번 강의에서 배울 것

### **혹시 이런 경험 있으신가요?**

- **서비스가 커지면서 조회가 점점 느려지는**데, 인덱스를 어떻게 붙여야 할지 몰라서 EXPLAIN 창만 멍하니 바라본 적 있나요?
- **JOIN이 너무 많아** “정규화한 게 문제인가?” 싶어 테이블을 합쳤더니, 이번엔 **쓰기 트랜잭션이 데드락**에 걸리기 시작합니다.
- 리플리카를 붙여 읽기 부하를 분산했는데, **“저장하자마자 안 보인다”** 는 QA 리포트가 쌓입니다. 복제 지연? 뭘 어떻게 해야 하죠?
- 새 기능 때문에 테이블 구조를 바꿔야 하는데, **다운타임 없이 DDL**을 날리는 방법이 막막해서 **주말 새벽 배포**를 계획한 적이 있나요?
- 이런 **DB 설계·운영 악순환**을 겪었다면, 이번 주차가 바로 해답을 드릴 차례입니다.

### **DB 설계란 무엇일까요?**

- 한 줄 정의: **“비즈니스 데이터를 어떻게 저장·연결·보호·확장할지 결정하는 설계도”**
- 흔히 ERD 그리기로 시작하지만, **정규화 ↔ 반정규화, 트랜잭션·락·샤딩·레플리카**까지 **데이터 생애 주기 전체**를 아우르는 의사결정 집합입니다.
- **ANSI/SPARC 3계층 모델**(External–Conceptual–Internal)을 떠올리면
    - **Conceptual**: ERD·정규화
    - **Internal**: 인덱스·파티션·스토리지·락
    - **External**: API·뷰·읽기 모델
- 결국 **“데이터를 잘못 설계하면 서비스가 성장할수록 발목을 잡는다”** 는 사실을 이해하는 게 출발점입니다.

### **왜 DB 설계가 중요할까요?**

- **성능 관점**
    - 인덱스 미스·풀스캔 한 번에 전체 서비스 **P95 지연이 수초**까지 치솟을 수 있습니다.
    - 파티션 키를 잘못 잡으면 특정 샤드만 **핫스팟**이 되어 장애가 반복됩니다.
- **정합성 관점**
    - 테이블을 과도하게 쪼개 두면 **JOIN 중 락 경합**으로 데드락·Phantom Read 발생.
    - 반대로 무작정 컬럼을 중복시키면 **데이터 불일치**가 눈덩이처럼 커집니다.
- **확장·비용 관점**
    - 초기엔 편한 스키마가, 몇 년 뒤 수십 TB 급에서 **OSC(Online Schema Change) 불가**라는 폭탄이 됩니다.
    - 복제 지연을 방치하면 리플리카 읽기 트래픽이 **데이터 오류를 낳아** 고객 컴플레인이 증폭됩니다.
- **운영·보안 관점**
    - 개인 정보 컬럼 위치·암호화 정책이 뒤죽박죽이면 GDPR/ISMS 심사 때 **벌금 리스크**가 현실화됩니다.

💬 **궁금증:** “정규화·CQRS·Shard·Lock… 전부 알아야 하나요?”

🙂 **답:** 모든 기법을 100 % 구현할 필요는 없습니다. 이번 강의는 **“어떤 상황에서 어떤 설계 카드가 효과적인가?”** 를 판단할 틀을 제공하는 것이 목표입니다.

- **정규화** → 데이터 일관성을 최우선할 때
- **반정규화** → 읽기 TPS>쓰기 TPS이며, 조인 비용이 병목일 때
- **락 전략** → 동시성 충돌 빈도·정합성 요구 레벨에 따라 달라집니다.
- **CQRS·Outbox** → 분산 시스템으로 확장될 때 “쓰기·읽기 책임”을 분리해 정합성과 성능을 동시에 잡는 패턴입니다.

<aside>
⛵

**이번 주차 목표**

</aside>

- **트랜잭션 설계 기초(ACID, 단위 구성)**를 통해 **데이터 정합성과 일관성의 기본 개념**을 익힘
- **데이터 모델링 기초**(정규화 ↔ 반정규화)를 바탕으로 **일관된 테이블 구조와 확장 가능한 스키마**를 설계함
- **관계 및 제약조건 설계**(FK, Unique, Check, NOT NULL 등)를 통해 **무결성과 실수 방지 구조**를 설계함
- **인덱스, 파티셔닝, 커버링 인덱스**를 활용해 **성능과 확장성까지 고려한 설계**를 구성함
- **복제 토폴로지와 읽기 스케일아웃 전략**을 이해하고, **지연 문제에 대응하는 구조**를 학습함
- **CQRS 및 Outbox 패턴 개론**을 통해 **분산 시스템으로의 자연스러운 확장 기반**을 체득함
- **Online DDL, GDPR, 거버넌스 체크리스트**를 통해 **운영·규제까지 고려하는 데이터 설계 감각**을 익힘

## 3. **트랜잭션 설계 기초**

### **트랜잭션이란?**

- **더 이상 나눌 수 없는 하나의 완결된 작업 단위**
- 모든 쿼리가 **모두 반영되거나, 전부 무효화되어야 함**
- 일부만 성공하거나 실패하면 안 되며, **시스템 신뢰성의 핵심 기초가 되는 단위**

### **트랜잭션 4대 특성 (ACID)**

| **속성** | **설명** | **예시** |
| --- | --- | --- |
| **Atomicity (원자성)** | 전부 성공 또는 전부 실패해야 함 | A → B로 이체: 출금 성공, 입금 실패 → 전체 롤백 |
| **Consistency (일관성)** | 트랜잭션 전후 상태는 항상 정합성을 유지해야 함 | A에서 빠진 만큼 B에 더해져야 전체 금액 같음 |
| **Isolation (격리성)** | 트랜잭션은 동시에 수행되어도 서로 영향을 주지 않아야 함 | 다른 트랜잭션의 중간 상태를 읽지 않음 |
| **Durability (지속성)** | 트랜잭션 완료 결과는 영구 반영됨 | COMMIT 이후 서버가 꺼져도 결과는 유지됨 |

### **실전 트랜잭션 단위 설계 예시**

> 상품 주문 흐름
> 
1. 주문 정보 입력
2. 재고 차감
3. 포인트 차감
4. 배송 정보 저장
5. → 모두 성공 시 COMMIT, 하나라도 실패 시 ROLLBACK

→ 이 전체 흐름이 **하나의 트랜잭션 단위**로 설계되어야 함

![image.png](attachment:2c7a346e-d58d-4f4d-9bb4-c38ce80bc845:image.png)

### **트랜잭션과 설계의 관계**

| **설계 포인트** | **트랜잭션 연관성** |
| --- | --- |
| 테이블 간 제약조건 (FK 등) | 참조 무결성을 트랜잭션 내에서 보장해야 함 |
| 락 범위 조정 | 격리 수준, 인덱스 설계와 연결됨 |
| Outbox 패턴 | 트랜잭션과 메시지 발행의 경계 설정 |
| 상태 전이 | 한 트랜잭션 내에서 상태 변경 완료되어야 함 (ex. 주문 → 결제완료 → 배송중) |

### **TIP**

- DBMS마다 기본 격리 수준이 다름 (MySQL은 REPEATABLE READ, PostgreSQL은 READ COMMITTED)
- 격리 수준이 높을수록 정합성은 올라가지만, 동시성 성능은 낮아짐 → 서비스 특성에 맞게 선택해야 함

## 4. DB 설계 원칙과 기본기

### 실무에서 자주 마주치는 문제 사례

- 서비스 초기에 단순하게 시작했지만, 컬럼이 점점 늘어나면서 테이블 구조가 복잡해지는 경우가 많음
- 여러 테이블을 조인하다 보니 결과가 엉키고, 일관성이 깨지는 사례가 자주 발생함
- 데이터를 전부 JSON 형태로 저장했더니 검색 속도와 필터 기능에서 병목이 발생함

### 데이터 모델링이란?

![https://wikidocs.net/1208](attachment:9140f101-796a-42ef-b441-58e61b3bb615:db_model.png)

https://wikidocs.net/1208

- 데이터 모델링은 실제 비즈니스에서 사용하는 개념을 데이터베이스의 테이블, 컬럼, 관계, 제약 등으로 표현하는 과정을 말함
- 일반적으로는 개념 모델 → 논리 모델 → 물리 모델 순서로 진행됨
    - **개념 모델**: 사용자와 개발자가 이해할 수 있는 수준에서 비즈니스 개체(예: 회원, 주문, 상품 등)와 그 관계를 도식화한 것임. ERD(Entity Relationship Diagram)가 대표적인 도구임.
    - **논리 모델**: 개념 모델을 기반으로 실제 테이블 구조에 가까운 형태로 다듬는 단계임. 각 엔터티에 키를 정의하고, 정규화를 적용해 관계와 제약 조건을 명확히 설정함.
    - **물리 모델**: 논리 모델을 바탕으로 실제 사용하는 DBMS의 특성과 성능을 고려해 최적화하는 단계임. 인덱스 생성, 파티셔닝 전략, 스토리지 포맷 등을 설계함.

### 모델링이 중요한 이유

| 발생할 수 있는 문제 | 모델링이 잘 되었을 때의 효과 |
| --- | --- |
| 데이터의 중복 또는 불일치 발생 | 정규화를 통해 데이터의 일관성을 보장할 수 있음 |
| 복잡한 JOIN으로 인한 성능 저하 | 필요한 부분만 반정규화하고 인덱스를 적용해 성능을 향상시킬 수 있음 |
| 트래픽이 늘면서 확장에 한계 도달 | 샤딩을 고려한 설계로 수평 확장을 유연하게 할 수 있음 |
| 개인정보 등 규제 이슈 대응 어려움 | 수명 주기와 암호화 설계를 미리 고려해 대응 체계를 갖출 수 있음 |

### 데이터 모델링 핵심 주제 요약

1. **정규화 단계** (1NF ~ 4NF, BCNF)
    - 테이블 내 데이터 중복과 이상현상을 제거하고 데이터 무결성을 높이는 데 목적이 있음
    - 쉽게 말하면, 같은 데이터가 여러 곳에 반복되거나 서로 충돌하지 않도록 테이블을 잘게 나누는 작업임.
    - 이를 통해 데이터를 추가하거나 수정할 때 발생할 수 있는 문제(예: 중복 저장, 데이터 불일치, 삭제 시 의도치 않은 데이터 손실 등)를 줄일 수 있음.
    - 1NF ~ 4NF, BCNF
        - **1NF (제1정규형)**:
            - 모든 컬럼이 원자값(atomic value)을 가지도록 구성함. 즉, 하나의 셀에는 하나의 값만 있어야 함.
            - 예: '구매한 상품' 컬럼에 "마우스, 키보드"가 같이 들어 있다면, 이를 각각 행으로 분리해 저장해야 함.
        - **2NF (제2정규형)**:
            - 기본 키의 일부에만 종속된 컬럼(부분 함수 종속)을 제거함. 복합 키를 사용하는 테이블에서 발생하기 쉬움. 모든 컬럼은 기본 키 전체에 의존해야 함.
            - 예를 들어, (서점ID, 도서ID)로 구성된 '판매 테이블'이 있다고 가정함. 그런데 여기에 '도서 제목'이라는 컬럼이 같이 들어 있다면 문제가 발생함. 도서 제목은 도서ID로만 결정되므로, 복합 키의 일부(도서ID)에만 종속된 셈임.
            - 이럴 경우 도서 정보를 따로 관리하는 '도서 테이블'로 분리하는 것이 바람직함.
            → 이렇게 하면 같은 도서 제목이 여러 번 반복 저장되는 것을 막을 수 있고, 도서 정보가 변경될 때도 한 곳만 수정하면 되므로 오류 가능성이 줄어듦.
        - **3NF (제3정규형)**:
            - 이행적 함수 종속(비-기본 키 컬럼이 또 다른 비-기본 키 컬럼에 의존하는 경우)을 제거함.
            - 컬럼 간 간접 의존을 없애서 설계를 단순하게 유지함.
            - 예: 도서 테이블에 '도서 ID', '출판사 ID', '출판사 주소'가 함께 있다면, 출판사 주소는 출판사 ID로만 알 수 있는 정보임. 이럴 경우 출판사 정보를 따로 테이블로 분리해 관리하는 것이 바람직함.
        - **BCNF (보이스-코드 정규형)**:
            - 모든 결정자가 후보 키이어야 함. 3NF보다 더 엄격한 조건이며, 후보 키가 여러 개 있을 때 적용함.
            - 예: 도서 대여 테이블에서 (회원 ID, 도서 ID)를 후보 키로 사용하는데, '대여 날짜'가 도서 ID만으로도 결정된다면, 이 경우 BCNF를 위반한 것임. 도서별 대여 가능일이 고정되어 있다면, 이를 별도 테이블로 분리해 해결할 수 있음.
        - **4NF (제4정규형)**:
            - 다치 종속(Multivalued Dependency)을 제거함. 하나의 키에 대해 서로 관련 없는 여러 값들이 반복 저장되면 데이터를 분리해야 함.
            - 예: 도서 테이블에 '도서 ID', '번역자', '리뷰어' 컬럼이 있다고 가정할 때, 하나의 도서가 여러 명의 번역자와 여러 명의 리뷰어를 가질 수 있다면, 이 정보는 따로 각각의 테이블로 분리해 관리하는 것이 좋음. → 같은 정보가 중복 저장되는 것을 방지하고 수정이 쉬워짐.
2. **반정규화 패턴**
    - 반정규화 패턴이란 정규화된 테이블 구조를 성능이나 운영 편의상 일부 되돌리는 설계 방식임. 데이터의 중복을 감수하더라도 조회 속도나 유지관리 측면에서 유리한 구조를 선택하는 것이 핵심임.
    - 집계 테이블
        - 자주 조회되는 통계를 미리 계산해서 저장해 두는 구조임. 예를 들어 매일 총 매출액을 계산하는 경우, 실시간으로 SUM 연산을 하지 않고 미리 계산한 값을 저장해두면 조회 속도가 크게 향상됨.
    - 중복 컬럼
        - 조인 없이 데이터를 바로 조회할 수 있도록 특정 컬럼 값을 다른 테이블에도 복사해 저장하는 방식임. 예를 들어 주문 테이블에 고객 이름을 직접 저장하면, 고객 테이블과 조인 없이 바로 이름을 출력할 수 있음. 중복 저장이지만 속도를 우선할 때 사용됨.
    - 이력 테이블
        - 변경 기록을 메인 테이블과 분리해 따로 저장하는 구조임. 예를 들어 회원 상태가 변경될 때마다 로그를 따로 남기는 테이블을 두면, 메인 테이블은 항상 최신 상태만 유지할 수 있어 성능과 유지관리 측면에서 유리함
3. **키 설계**
    - 자연 키는 실제 비즈니스에서 고유하게 식별할 수 있는 값(예: 주민등록번호, 이메일 주소 등)을 사용하는 방식이고, Surrogate 키는 시스템에서 자동으로 생성하는 인위적인 식별자(예: 자동 증가 ID, UUID 등)를 의미함. 자연 키는 사람이 이해하기 쉬운 의미를 가지고 있지만, 나중에 변경될 가능성이 존재함. 반면, Surrogate 키는 비즈니스 의미는 없지만 절대 변경되지 않으며, 샤딩이나 인덱스 구성 시 더 유리한 경우가 많음.
    - 예를 들어 회원 테이블에서 이메일 주소를 PK로 사용할 수도 있지만, 이메일이 바뀌는 경우가 있기 때문에 Surrogate 키인 auto_increment ID나 UUID를 사용하는 것이 더 안정적임. 이메일 주소는 UNIQUE 제약조건으로 따로 관리하면 됨. 이렇게 하면 내부적으로 참조하기 쉬우며 외부 시스템 연동이나 확장성 면에서도 유리함.
    - 어떤 키를 선택할지는 해당 데이터의 변경 가능성, 외부 시스템과의 연동 여부, 조회 빈도, 시스템 확장성 요구사항 등을 종합적으로 고려해 결정해야 함.
4. **관계 및 제약 조건 설계**
    - 외래 키(FK), 고유 제약조건(Unique), 체크 제약(Check) 등을 적절히 설정해야 데이터 무결성을 유지할 수 있음
    - 예를 들어, 주문 테이블에서 customer_id가 고객 테이블을 참조하도록 외래 키를 설정하면, 존재하지 않는 고객 ID로 주문을 입력하는 것을 방지할 수 있음.
    또한 이메일 컬럼에 Unique 제약조건을 걸어 중복 가입을 방지하고, 수량(quantity) 컬럼에 CHECK(quantity > 0) 조건을 설정하면 잘못된 입력을 차단할 수 있음.
5. **도메인 값 객체(Value Object)**
    - 금액, 수량, 단위 등 의미가 있는 값들은 독립적인 타입으로 관리하는 것이 유지보수에 유리함.
    예를 들어 '가격'이라는 컬럼을 단순히 숫자로 저장하기보다는 금액 객체를 만들어 통화 단위(원, 달러 등), 소수점 처리, 음수 허용 여부 등의 규칙을 캡슐화하면 이후 계산이나 비교 작업이 일관되게 유지됨.
    마찬가지로 '수량'도 단위(개, 박스 등)가 명확한 타입으로 분리되어 있으면 실수 입력을 방지하고, 도메인 규칙 변경 시 반영이 쉬워짐.
    - 예: 단순히 테이블에 `price` 컬럼을 숫자형(INT 또는 DECIMAL)으로 두고 `price = 1000`이라고만 저장하는 대신, `money_amount`와 `currency_code` 컬럼을 나누어 관리하거나, 금액 정보를 캡슐화할 수 있는 별도 테이블 또는 뷰를 활용함. 예를 들어 `products` 테이블에서 가격 정보를 다음과 같이 구성할 수 있음:
        
        ```sql
        CREATE TABLE products (
          product_id BIGINT PRIMARY KEY,
          name VARCHAR(100),
          price_amount DECIMAL(10, 2),
          price_currency CHAR(3)  -- 예: 'KRW', 'USD'
        );
        ```
        
    

### 정규화 단계 적용 예시 (2NF → 3NF 개선)

```
-- 기존 구조: product_name이 product_id에 종속되지만 order_item 테이블에 같이 있음
CREATE TABLE order_item (
  order_id BIGINT,
  product_id BIGINT,
  product_name VARCHAR(50),
  quantity INT,
  PRIMARY KEY(order_id, product_id)
);

-- 개선된 구조: product 테이블로 분리하여 종속성 제거
CREATE TABLE product (
  product_id BIGINT PRIMARY KEY,
  product_name VARCHAR(50)
);
CREATE TABLE order_item (
  order_id BIGINT,
  product_id BIGINT,
  quantity INT,
  PRIMARY KEY(order_id, product_id),
  FOREIGN KEY(product_id) REFERENCES product(product_id)
);
```

### 반정규화를 고려할 수 있는 상황

| 상황 | 적용할 수 있는 패턴 | 기대 효과 |
| --- | --- | --- |
| 대시보드에 자주 쓰이는 집계 값이 필요함 | 집계 테이블 별도로 구성 | 조회 시 GROUP BY 비용을 줄일 수 있음 |
| 프론트 화면에서 여러 조인이 필요함 | Lookup 컬럼을 중복 저장 | 조인 제거로 지연 시간을 단축할 수 있음 |
| 특정 데이터의 이력을 관리해야 함 | 히스토리 테이블 분리 | 메인 테이블을 가볍게 유지하고 보관 주기를 설정할 수 있음 |

### 락과 성능을 고려한 설계 포인트

- 인덱스를 잘못 설정하면 Gap Lock이 발생해 동시성 문제가 생길 수 있음 → 고유한 인덱스나 조인 조건이 중요함
- 단순한 증가형 PK는 특정 페이지에 데이터가 몰리면서 성능 병목을 일으킬 수 있음 → 분산 키 또는 UUID 등의 대안 고려함

### 모델링과 트랜잭션의 연결

- 너무 과하게 정규화하면 조인 횟수가 많아져 경합이 발생함
- 반대로 과도한 반정규화는 중복 업데이트가 늘어나면서 데드락 발생 확률을 높일 수 있음

### TDD(테스트 주도 개발)와 스키마 설계

| 단계 | 모델링에 주는 신호 |
| --- | --- |
| Red | 테스트 데이터 구성이 복잡하면 → 테이블 구조를 나누어야 함 |
| Green | 속도가 느리면 → 쿼리 튜닝이나 인덱스 추가를 고려해야 함 |
| Refactor | 테스트 중 중복된 데이터가 많다면 → 공통 테이블로 정리하거나 도메인 분리를 고려해야 함 |

### 이 모듈을 통해 달성해야 할 목표

- 정규화와 반정규화의 기준을 이해하고, 실제 서비스에 적용할 수 있어야 함
- 키와 제약 조건 설계가 동시성, 확장성, 무결성에 어떤 영향을 주는지 판단할 수 있어야 함
- 테스트 작성 중 나타나는 구조적 문제 신호를 보고, 스키마 리팩터링으로 이어지는 사고 흐름을 만들 수 있어야 함

## 5. **관계·제약 조건 설계**

### 핵심 용어 먼저 살펴보기

- **무결성(Integrity)**: 데이터가 항상 정확하고 일관된 상태임을 뜻함. 테이블 구조·제약 조건을 통해 잘못된 값(예: 잘못된 참조, 허용 범위를 벗어난 숫자)이 저장되지 않도록 보장함. **예) 이메일이 PK 없는 상태로 삽입되면 제약 오류로 거부됨**.
- **참조 무결성**: 부모‑자식 테이블 관계에서, 자식 레코드가 반드시 존재하는 부모 레코드를 가리키도록 강제하는 규칙임. 외래 키(FK)로 구현함. **예) 주문 테이블에 없는 user_id를 삽입하면 FK 오류 발생**.
- **엔티티 무결성**: 각 레코드가 고유한 식별자(PK)를 가져야 하며 NULL이 될 수 없다는 원칙임. Primary Key 제약으로 보장함. **예) user_id(PK)가 NULL이면 INSERT가 거부됨**.
- **도메인 무결성**: 컬럼 값이 지정된 범위·패턴·집합을 벗어나지 않아야 한다는 규칙임. CHECK, NOT NULL, ENUM 등이 여기에 해당함. **예) quantity 컬럼이 -1이면 CHECK 제약 위반**.
- **멱등성(Idempotency)**: 같은 요청을 여러 번 보내더라도 최종 결과가 한 번 호출한 것과 동일하게 유지되는 성질임. 결제나 메시지 발송 API에서 `(user_id, idempotency_key)` 같은 복합 Unique 제약으로 보장할 수 있음. **예) 같은 idempotency_key로 두 번 결제 요청해도 결제 레코드는 1건만 저장됨**.
- **데드락(Deadlock)**: 두 트랜잭션이 서로 가진 락을 기다리며 무한 대기 상태에 빠지는 현상임. 락 획득 순서를 통일하거나 재시도(back‑off) 로직으로 해결함. **예) 트랜잭션 A는 orders를, B는 payment를 먼저 락 후 서로 상대 테이블을 기다리다 대기 상태**.

### 1. 외래 키(Foreign Key)

- **하는 일** : 두 테이블(부모‑자식) 간의 **참조 무결성**을 보장함. 부모 PK가 없는 값이 자식 FK에 들어오는 것을 차단함.
- **장점** : 잘못된 데이터 유입을 근본적으로 방지해 버그·보고서 오류를 사전에 줄여 줌.
- **단점** : 트랜잭션마다 무결성 검사를 수행하므로 대량 일괄 삽입(Bulk Insert) 시 성능이 다소 저하될 수 있음.
- **ON DELETE / ON UPDATE** 동작 비교
    
    
    | 옵션 | 삭제·변경 시 동작 | 추천 사례 | 주의할 점 |
    | --- | --- | --- | --- |
    | CASCADE | 부모 삭제 → 자식 자동 삭제 | 게시물‑댓글, 주문‑주문상세 | 과도 사용 시 의도치 않은 데이터 손실 위험 |
    | SET NULL | FK를 NULL로 변환 | 게시글 작성자 탈퇴 후 글만 유지 | FK 컬럼이 NULL 허용이어야 함 |
    | RESTRICT / NO ACTION | 부모에 자식이 존재하면 삭제 거부 | 회원이 주문 기록이 있을 때 탈퇴 차단 | UI에서 오류 메시지 처리 필요 |
- **실전 설정 예시**
    
    ```sql
    ALTER TABLE orders
      ADD CONSTRAINT fk_orders_user
        FOREIGN KEY (user_id)
        REFERENCES user(user_id)
        ON DELETE RESTRICT    -- 회원 탈퇴 시 주문 보존
        ON UPDATE CASCADE;    -- PK 변경 시 자동 반영 (잘 안 쓰지만 예시용)
    
    ```
    
- **성능 팁** : FK 컬럼에 **동일 순서**의 Index를 반드시 생성함. 없으면 삭제·업데이트 때 테이블 스캔이 발생해 락 경합이 길어짐.

### 2. 고유 제약(Unique Constraint)

- **하는 일** : 테이블 내부에서 **중복 레코드** 생성을 방지함.
- **단일 컬럼 예시**
    
    ```sql
    email VARCHAR(255) NOT NULL UNIQUE  -- 이메일 중복 가입 차단
    
    ```
    
- **복합 컬럼 예시** : API 멱등성, 다중 키 제약
    
    ```sql
    ALTER TABLE payment
      ADD CONSTRAINT uq_payment_user_key
        UNIQUE (user_id, idempotency_key);
    
    ```
    

### 3. 체크 제약(Check Constraint)

- **하는 일** : 컬럼 값이 **범위·패턴**을 벗어나면 데이터 조작을 거부함.
- **숫자 범위 예시**
    
    ```sql
    price DECIMAL(10,2) CHECK (price >= 0)
    
    ```
    
- **문자 패턴 예시** (PostgreSQL Regex)
    
    ```sql
    username VARCHAR(20)
      CHECK (username ~ '^[a-zA-Z0-9_]{4,20}$');
    
    ```
    
- **복합 Check 제약** : 여러 컬럼 동시 검증
    
    ```sql
    CHECK (start_date < end_date)
    
    ```
    
- **주의** : DBMS 버전에 따라  CHECK가 동작하지 않을수도 있음

### 4. NOT NULL & DEFAULT

- **NOT NULL** : 컬럼이 **반드시** 값을 가져야 함. NULL 여부가 로직 분기를 복잡하게 하므로 가능하면 제한함.
- **DEFAULT** : 입력 생략 시 자동값을 세팅해 불필요한 코드 분기를 줄여 줌.
- **콤보 활용 예시**
    
    ```sql
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
                 ON UPDATE CURRENT_TIMESTAMP
    
    ```
    
- **실전 팁** : 타임스탬프 컬럼은 **UTC(표준 기준 시간)**로 저장하고 앱 레이어에서 지역 시간대로 변환함.

### 5. 지연(Deferrable) 제약의 활용

- 일부 DB(PostgreSQL)는 트랜잭션 종료 시점까지 FK·Unique 제약 검사를 **지연**할 수 있음.
- 다단계 적재(순환 참조 테이블) 시 INSERT 순서 문제를 우회함.
    
    ```sql
    SET CONSTRAINTS ALL DEFERRED;
    
    ```
    
- 실무에서는 마이그레이션 스크립트나 일괄 데이터 변환 작업에서 유용함.

### 6. 통합 예시

```sql
CREATE TABLE user (
  user_id    BIGINT PRIMARY KEY AUTO_INCREMENT,
  email      VARCHAR(255) UNIQUE NOT NULL,
  name       VARCHAR(100)        NOT NULL,
  deleted_at TIMESTAMP NULL
);

CREATE TABLE orders (
  order_id     BIGINT PRIMARY KEY AUTO_INCREMENT,
  user_id      BIGINT NOT NULL,
  status       VARCHAR(20) NOT NULL DEFAULT 'READY',
  total_amount DECIMAL(10,2) NOT NULL CHECK (total_amount >= 0),
  requested_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY fk_orders_user (user_id)
    REFERENCES user(user_id)
    ON DELETE RESTRICT
);

-- 결제 테이블: 멱등성 보장을 위해 복합 Unique 사용
CREATE TABLE payment (
  payment_id       BIGINT PRIMARY KEY AUTO_INCREMENT,
  order_id         BIGINT NOT NULL,
  user_id          BIGINT NOT NULL,
  idempotency_key  CHAR(36) NOT NULL,
  amount           DECIMAL(10,2) NOT NULL CHECK(amount >= 0),
  created_at       TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  UNIQUE uq_payment_user_key (user_id, idempotency_key),
  FOREIGN KEY (order_id) REFERENCES orders(order_id) ON DELETE CASCADE,
  FOREIGN KEY (user_id)  REFERENCES user(user_id)
);

```

### 7. 기억해야 할 포인트

1. **DB 무결성 > 애플리케이션 로직** : 서버 코드가 버그를 일으켜도 DB 제약이 마지막 방어선이 됨.
2. **인덱스와 제약은 짝** : FK·Unique에는 자동 또는 수동 인덱스가 필요함. 없는 경우 쿼리가 테이블 스캔과 락 경합을 유발함.
3. **제약 추가 순서** : 대용량 테이블에 제약을 추가할 때는 Online DDL(gh‑ost 등)이나 배치 윈도우를 활용해 서비스 중단을 피함.
4. **단계적 도입** : 프로토타입 단계에서는 FK·Check를 잠시 생략하고, 기능 검증 후 강화해도 됨. 하지만 Unique·NOT NULL 같은 기본 제약은 초기에 잡아두는 편이 이후 코드 품질을 높여 줌.

<aside>
🔥

최종 목표는 “애플리케이션 코드를 믿지 못해도 DB 데이터만큼은 언제나 신뢰할 수 있도록” 만드는 것임.

</aside>

## 6. **동시성 설계 원칙**

<aside>
❗

**전체 동시성·트랜잭션 심화는 다음 주 강의에서 다룹니다.**
여기서는 **DB 설계 관점**에서 꼭 짚고 넘어가야 할 핵심 한 가지만 기억하면 충분합니다.

[https://techblog.woowahan.com/?s=동시성](https://techblog.woowahan.com/?s=%EB%8F%99%EC%8B%9C%EC%84%B1)

</aside>

### 핵심 용어 먼저 살펴보기

- **격리 수준**: 동시에 실행되는 트랜잭션이 서로에게 얼마나 보이지 않도록 할지 결정함.
- **락(Lock)**: 동시에 같은 행을 건드리지 못하게 잠그는 장치임.
- **Gap Lock**: 범위 락으로, **행과 행 사이의 ‘빈 칸’까지 선점**함. 비유하면 *영화관에서 5·10번 좌석만 판매된 상태에서 6~9번 좌석도 “예약 중” 스티커를 붙여 다른 관객(트랜잭션)이 끼어들지 못하게 하는 것*과 같음.
- **데드락**: 서로가 가진 락을 기다리다 무한 대기 상태에 빠지는 현상임.

### 1. 격리 수준 체크만으로 절반은 해결됨

- **`READ COMMITTED`**
    - **Dirty Read**(다른 트랜잭션 미‑커밋 데이터 읽기)를 막음.
    - 하지만 한 트랜잭션 안에서 같은 행을 두 번 읽으면 값이 바뀔 수 있음(Non‑repeatable Read 허용).
    - **쉬운 비유**: 시험 답안을 "제출(커밋)한 것만 볼 수 있다"는 규칙. 아직 수정 중인 답안은 못 봄.
    - **적합한 곳**: 뉴스·게시판 목록처럼 읽기 위주 화면. Gap Lock이 적어 동시성이 높음.
- **`REPEATABLE READ`** *(MySQL 기본값)*
    - 트랜잭션이 첫 SELECT를 실행한 순간의 스냅샷을 끝까지 유지함.
    - Dirty Read는 물론 Non‑repeatable Read도 방지함. MySQL은 Gap Lock까지 걸어 팬텀도 대부분 막음.
    - **쉬운 비유**: 시험장 문을 잠그고, 시험 보는 동안에는 다른 사람이 답안을 고쳐도 내 시험지는 안 바뀜.
    - **적합한 곳**: 장바구니 합계 계산, 재고 차감처럼 "읽고 곧바로 쓰는" 패턴이 많은 로직.
- **`SERIALIZABLE`**
    - 모든 SELECT가 공유/범위 락을 잡아 *실질적으로 순차 처리*처럼 보장함. 팬텀까지 100 % 차단.
    - 성능은 가장 느림(락 경합·대기 증가).
    - **쉬운 비유**: 서점 계산대가 한 줄밖에 없어 손님을 한 명씩만 처리하는 방식.
    - **적합한 곳**: 회계, 결제 승인, 금융 이체 등 하나라도 꼬이면 안 되는 업무.
- **Tip** : 같은 DB 안에서도 트랜잭션마다 격리 수준을 지정할 수 있음.

### 2. PK/인덱스 구조가 락 경합을 좌우함

- 순차 증가형 PK만 쓰면 마지막 페이지에 삽입이 몰림. Insert Hotspot 발생함.
- 해결책으로 **UUID v4** 또는 **분산 키**를 사용함. 행이 여러 페이지로 분산됨.
- 자주 쓰는 WHERE 컬럼은 반드시 인덱스를 가짐. 인덱스가 없으면 레코드가 아닌 **테이블 전체**가 잠김.

### 3. 데드락은 락 순서 통일만으로 대부분 예방됨

- 트랜잭션마다 테이블 접근 순서를 **users → orders → payments**로 고정함.
- 순서가 뒤바뀌면 교차 락이 생김. MySQL은 데드락 감지 후 한 트랜잭션을 죽임.

### 4. DB 설계 단계에서 할 일 체크리스트

1. **격리 수준 문서화**함. 테이블별 표를 만들어 정리함.
2. **PK 분산 전략**을 정의함. 샤딩 키나 UUID 여부를 결정함.
3. **복합 인덱스**를 미리 설계함. 자주 쓰는 검색 키를커버함.
4. **락 순서**를 코드 컨벤션에 명시함. PR 리뷰 시 확인함.

## 7. **인덱스·통계·쿼리 설계**

### **인덱스란?**

- 인덱스는 테이블에 **찾아가기 위한 목차 역할**을 하는 구조임.
- WHERE 조건이 있더라도 인덱스가 없으면 **테이블 전체를 스캔**하게 되어 성능 저하가 발생함.
- RDB 대부분은 **B-Tree 인덱스**를 기본값으로 사용함. 정렬된 트리 구조로 되어 있어 =, BETWEEN, LIKE 'abc%', ORDER BY 쿼리에 강함.
- 인덱스는 SELECT뿐 아니라 JOIN, ORDER, GROUP BY에도 영향을 줌

### **복합 인덱스의 순서가 중요한 이유**

- 여러 컬럼을 묶은 인덱스는 **왼쪽부터 순서대로만** 사용할 수 있음.
- WHERE 절에서 자주 사용하는 순서로 구성해야 효과적임.
- 복합 인덱스는 “선별도 높은 컬럼”을 앞에 두는 것이 일반적인 원칙임

```
CREATE INDEX idx_user_name_email ON user(name, email);

-- name만 사용하는 쿼리: 인덱스 사용됨
SELECT * FROM user WHERE name = '홍길동';

-- name + email 쿼리: 인덱스 사용됨
SELECT * FROM user WHERE name = '홍길동' AND email = 'a@b.com';

-- email만 조건인 쿼리: 인덱스 사용 안 됨
SELECT * FROM user WHERE email = 'a@b.com';
```

### **커버링 인덱스(Covering Index)**

- 인덱스에 포함된 컬럼만으로 SELECT 쿼리를 처리할 수 있으면 테이블 자체를 보지 않아도 됨.
- 이를 **커버링 인덱스**라고 하며, 디스크 I/O가 줄어들어 성능이 크게 향상됨.

```
CREATE INDEX idx_order_user_status ON orders(user_id, status);

-- 조회 컬럼이 모두 인덱스에 포함되어 있어 covering index 사용됨
SELECT user_id, status FROM orders WHERE user_id = 123;
```

### **인덱스 설계 실전 팁**

| **상황** | **인덱스 설계 포인트** |
| --- | --- |
| WHERE user_id = ? | 단일 컬럼 인덱스 생성 |
| 최근 일주일 데이터 조회 | created_at DESC 인덱스 생성 |
| 정렬이 자주 발생하는 컬럼 | ORDER BY 방향까지 고려한 인덱스 구성 |
| 상태 + 날짜 필터 조건 자주 사용 | 복합 인덱스: status, created_at |
| LIKE 'abc%' | B-Tree 인덱스 동작함 |
| LIKE '%abc%' | 인덱스 동작 안 함 → Fulltext 또는 검색엔진 고려 |

### **EXPLAIN으로 쿼리 성능 분석**

- EXPLAIN 명령어를 통해 쿼리 실행 계획을 확인할 수 있음

```
EXPLAIN SELECT * FROM orders WHERE user_id = 123 AND status = 'PAID';
```

| **항목** | **의미** |
| --- | --- |
| type | 접근 방식 (ALL = Full Scan, ref = 인덱스 참조 등) |
| key | 실제 사용된 인덱스 이름 |
| rows | 스캔 대상 행 수 추정 |
| Extra | Using index / Using where 등 부가 정보 |

### **통계 갱신 (ANALYZE)**

- DBMS는 쿼리 계획을 세울 때 내부 통계를 사용함
- 테이블이 자주 변경되면 통계가 낡아 잘못된 실행 계획을 유도할 수 있음
- 주기적으로 통계를 갱신해야 쿼리 최적화가 정상적으로 작동함

```
-- PostgreSQL
ANALYZE user;

-- MySQL
ANALYZE TABLE user;
```

### **인덱스 설계 시 주의사항**

1. **인덱스는 많을수록 좋은 게 아님**
    
    → INSERT/UPDATE 성능이 떨어지고, 디스크 용량도 늘어남
    
2. **사용되는 쿼리 기준으로 구성해야 함**
    
    → 단순히 컬럼 개수만 보고 인덱스를 만들면 무용지물이 됨
    
3. **조인 조건 컬럼에도 인덱스 필요함**
    
    → 조인 성능은 대부분 인덱스 유무에 따라 갈림
    

## **정리: 인덱스 설계 핵심 체크리스트**

| **항목** | **설명** |
| --- | --- |
| WHERE 조건 컬럼 | 자주 쓰이면 인덱스 필요 |
| 정렬 기준 컬럼 | 정렬 방향 포함해 인덱스 설계 |
| 복합 조건 WHERE | 자주 조합되는 순서로 복합 인덱스 구성 |
| SELECT 대상이 인덱스 포함이면 | covering index로 처리 가능 |
| 인덱스 너무 많음 | 쓰기 성능 저하, 유지 부담 발생함 |

### 실전 조회 성능 최적화 전략

> 인덱스 튜닝만으로 해결되지 않는 경우, 조회용 구조 자체를 다르게 가져가는 전략이 필요
> 
1. 범위 조건 이후 인덱스 무효화 주의
- 복합 인덱스에서 범위 조건 (`<`, `>`, `BETWEEN`)이 들어가면 **그 뒤 컬럼은 인덱스가 무시**됨
- 특히 시간 범위 조건이 앞에 오고, 뒤에 자주 필터링하는 조건이 있을 경우 주의
- **카디널리티가 높은 컬럼을 앞에** 배치하고, **범위 조건은 마지막**에 가깝게 구성해야 함
    
    ```sql
    -- 인덱스 (user_id, created_at, status)
    WHERE user_id = 123 AND created_at > '2024-01-01' AND status = 'PAID'
    -- → created_at 이후인 status는 인덱스 사용 안 됨
    ```
    

1. WHERE 조건별 인덱스 적용 전략
- **AND vs OR**
    
    
    | **조건** | **인덱스 활용도** | **설명** |
    | --- | --- | --- |
    | AND | 높음 | 조건이 쌓일수록 결과 후보군(ROW 수)이 줄어들기 때문에 **인덱스 효율 증가** |
    | OR | 낮음 | 각 조건별로 결과를 UNION처럼 병합하기 때문에 **풀스캔 위험 증가** |
    
    ```
    -- 성능이 안 좋은 경우
    SELECT * FROM orders WHERE status = 'PAID' OR user_id = 123;
    
    -- 더 나은 방식 (조건 분리)
    SELECT * FROM orders WHERE status = 'PAID'
    UNION
    SELECT * FROM orders WHERE user_id = 123;
    ```
    

- **= 와 IN은 인덱스 다음 컬럼까지 활용 가능**
    
    
    | **연산** | **인덱스 다음 컬럼 활용** | **예시** |
    | --- | --- | --- |
    | = | O | product_id = 1 → 다음 컬럼도 인덱스 사용 |
    | IN | O | product_id IN (1,2) → 여러 번의 = 수행과 같음 |
    | <, >, BETWEEN | ✖ | 범위 조건 이후 컬럼은 인덱스 미사용 |
    
    ```
    -- 복합 인덱스 (product_id, ordered_at, status)
    WHERE product_id IN (1,2) AND ordered_at > '2024-01-01' AND status = 'PAID';
    
    -- 위 쿼리의 인덱스 활용
    → product_id = OK
    → ordered_at > OK
    → status = X (범위 조건 이후 컬럼 무효화)
    ```
    

1. Sync Schedule Strategy

<aside>
🔎

실시간성과 정합성의 Trade-Off 를 극복하기 위해 DB I/O 를 줄이고 `언젠가 정합성이 맞아 떨어지는` 환경을 구성하는 전략

</aside>

- 전략적으로 실시간 업데이트나 값을 조회하는 것이 아닌 `통계` 데이터를 활용하는 방법도 있음
- 앞서 말했던 자주 삽입, 수정되는 데이터에 대해 Index 를 적용할 경우 “배보다 배꼽이 커지는” 문제가 발생할 수 있음 ( 인덱스 또한 공간을 차지하므로 )
- 주기적으로 통계 데이터를 **Batch Process** 를 통해 취합하고 Sync 를 맞추는 테이블을 생성
- 통계 데이터를 조회할 땐 통계용 테이블만을 조회 ( 조회 연산 성능 향상 )

      (유사 패턴 keyword: [materialized view pattern](https://youtu.be/8OFTB57G9IU?t=1294))

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/b65f2ac3-5d50-418b-95f3-99488a3a35a2/Untitled.png)

## 8. **읽기 스케일아웃·복제 지연 대응 전략**

### **리플리카를 붙였는데 문제가 생긴다?**

- 초당 수천 건 이상 요청이 몰리는 서비스에서는 단일 DB 인스턴스로는 감당이 어려움.
- 그래서 대부분 **읽기 요청은 리플리카(복제 DB)로 분산**시키는 구조를 택함.
- 하지만 리플리카 구조를 쓰면 다음과 같은 문제가 함께 발생함:

| **상황** | **설명** |
| --- | --- |
| 저장 직후 데이터가 안 보임 | Master에는 INSERT됐지만, Replica에는 아직 반영되지 않음 |
| QA 테스트에서만 오류 발생 | 테스트는 DB에 바로 쓰고 바로 읽는 경우가 많음 → 복제 지연 노출 |
| Redis보다 결과가 늦음 | 캐시에는 최신값이 있는데 Replica에는 없음 → 결과 불일치 발생 |

### **복제 지연이 생기는 원인**

- 대부분의 RDB(MySQL, PostgreSQL 등)는 **비동기 복제**를 기본으로 사용함.
- 마스터에서 COMMIT된 트랜잭션이, 리플리카에서 적용되기까지 **수 ms~수 초 차이**가 발생할 수 있음.
- 특히 대량 쓰기나 대형 DDL 이후에는 **수 초 이상 지연**도 발생함.

```
Client → Master INSERT
       ↘
        Replica SELECT (아직 INSERT 반영 전)

→ SELECT 결과: INSERT 안 된 것처럼 보임
```

### **실무 대응 전략**

### **1. 쓰기 후 즉시 읽기 패턴은 무조건 Master로**

- 리플리카 지연 문제는 결국 **“쓰기 직후의 읽기”**에서 터짐.
- 예를 들어 “회원가입 직후 마이페이지 진입” 같은 흐름은 **Master를 강제로 사용**해야 함.
- 대부분의 ORM 또는 커넥션 풀러에서 마스터/리더 선택 기능을 제공함
- 쓰기 직후에는 “지연 없는 읽기”를 위해 반드시 Master를 사용해야 함

### **2. 비즈니스 로직에 따라 DB 선택 기준을 나눔**

| **요청 종류** | **권장 DB** |
| --- | --- |
| POST / PATCH 등 쓰기 요청 | 무조건 Master |
| GET 중에서도 쓰기 직후 데이터 확인 | Master |
| 일반적인 목록 조회 / 캐시 조회 | Replica 가능 |
| 배치성 조회 / 통계 | Replica 또는 별도 분석 DB |

### **3.복제 지연 감시 지표 확보**

- Seconds_behind_master(MySQL), pg_stat_replication(PostgreSQL) 등을 통해 리플리카 상태를 모니터링할 수 있음
- 리더 DB가 일정 시간 이상 지연되면 알람을 발생시키거나, **자동으로 Master fallback**되도록 구성할 수 있음

```
-- MySQL에서 지연 확인
SHOW SLAVE STATUS\G
```

### **4.비동기 이벤트 후 데이터 조회는 지연 감안**

- 예를 들어 “포인트 적립 후 적립 내역을 조회”하는 경우는,
    - 캐시를 쓰거나
    - 응답 메시지에 바로 적립 금액을 포함시키거나
    - sleep + retry를 감안하는 방식이 현실적임

---

## **정리: 읽기 스케일아웃 설계 시 유의사항**

1. 리플리카는 지연이 발생할 수 있는 구조임을 전제로 설계함
2. **쓰기 후 읽기**는 반드시 마스터에서 처리함
3. **Master/Replica 선택 기준을 비즈니스별로 정리**해두고, 팀 컨벤션으로 공유함
4. https://aws.amazon.com/ko/rds/features/read-replicas/

## 9. **파티셔닝 & 샤딩 전략**

### **테이블은 왜 쪼개야 할까?**

- 서비스가 성장하면서 테이블에 수억 건 이상의 데이터가 쌓이면, **인덱스 성능이 한계**에 도달하게 됨
- 특정 컬럼 값에 쿼리가 집중되면 **데이터가 한쪽에 몰려 성능 병목**이 발생함
- 쓰기 트래픽이 급증하면 **단일 노드에서 디스크·CPU·IO 한계**에 부딪히게 됨

→ 이때 선택할 수 있는 대표 전략이 **파티셔닝(partitioning)**과 **샤딩(sharding)**임

### **파티셔닝(Partitioning)이란?**

- **하나의 테이블을 내부적으로 여러 물리적 파티션으로 분할**해 저장하는 기능임
- DBMS가 단일 테이블처럼 보이게 해주므로, 쿼리는 동일하게 작성해도 내부적으로는 더 적은 범위만 탐색하게 됨
- **OLAP(분석형)**이나 **대용량 로그성 데이터** 처리에 자주 사용됨
- MySQL은 InnoDB에서 파티셔닝 지원이 제한적이므로, 버전/엔진 호환성 확인 필요

### **대표 파티션 방식**

| **방식** | **설명** | **예시** |
| --- | --- | --- |
| Range | 특정 범위로 분할 | 2024-01-01 ~ 2024-01-31, 2024-02-01 ~ ... |
| List | 값 목록 기반 분할 | region IN ('KR', 'JP'), ('US', 'CA') |
| Hash | 해시 값 기반 분할 | user_id % 4 → 4개의 파티션에 균등 분산 |
| Composite | 범위 + 해시 결합 | 월별 분할 + 유저 ID 해시 등 |

### **장점**

- 인덱스 크기 자체가 작아지므로 쿼리 탐색 속도 향상됨
- 파티션 단위로 **백업·삭제·보관 정책 적용이 쉬움**
- INSERT도 파티션 별로 분산되어 **락 경합이 줄어듦**

### **단점**

- 파티션 키가 잘못 설정되면 **한쪽으로만 몰리는 핫스팟 현상** 발생함
- 파티션 키 조건이 쿼리에 포함되지 않으면 **오히려 성능 저하** 가능성 있음

---

### **샤딩(Sharding)이란?**

- 단일 DB가 감당할 수 없는 수준의 데이터·트래픽이 발생할 경우, **DB 자체를 수평 분할**하는 전략임
- 각각의 샤드(Shard)는 **독립적인 DB 인스턴스**로 존재하며, 물리적으로 분산되어 있음
- 샤딩은 "처음부터" 하는 게 아니라, **용량·성능 한계가 보일 때** 도입하는 게 일반적임
- https://d2.naver.com/helloworld/14822

### **샤딩 구성 예시**

| **샤드** | **샤딩 기준** | **포함 유저** |
| --- | --- | --- |
| shard_1 | user_id % 4 = 0 | user_id 1000, 1040 등 |
| shard_2 | user_id % 4 = 1 | user_id 1001, 1041 등 |
| shard_3 | … | … |

### **장점**

- DB 단위로 분산되므로 **물리적 IOPS·CPU·네트워크 병목을 분산**할 수 있음
- 샤드 단위로 장애 격리가 가능함 → 하나의 샤드에 장애가 나도 전체 서비스는 유지됨
- 무중단 증설이 가능함 → **샤드를 늘려가며 수평 확장**

### **단점**

- **Cross-Shard Join이 불가능**함 → Join할 데이터는 동일 샤드에 존재해야 함
- **샤딩 키 선택이 핵심** → 불균형하게 분포되면 샤드 간 부하 편중 발생
- 샤드 개수가 늘어나면 운영 복잡도 증가 → 모니터링, 배포, 장애 대응 모두 어려워짐

---

### **파티셔닝 vs 샤딩**

| **구분** | **파티셔닝** | **샤딩** |
| --- | --- | --- |
| 분할 단위 | 테이블 내부 (파티션) | DB 인스턴스 자체 (샤드) |
| 적용 범위 | 동일 DB 내에서 작동 | 물리적으로 분리된 DB |
| 장점 | 쿼리 변경 없음, 유지보수 쉬움 | 성능·용량 확장에 유리 |
| 단점 | 복잡한 파티션 조건 필요 | Cross-Shard Join 불가, 운영 복잡도 ↑ |
| 대표 사용처 | 대용량 로그, 기간별 통계 | 사용자 데이터, 주문·결제 등 개별 처리 가능 도메인 |

---

### **실무 적용 기준**

| **상황** | **추천 방식** | **이유** |
| --- | --- | --- |
| 테이블이 수천만 건 이상으로 성장함 | 파티셔닝 | 인덱스 범위 줄이고, 관리 편의성 확보 |
| 특정 키(user_id 등)로 트래픽이 집중됨 | 샤딩 | 단일 DB의 병목 해소, 분산 처리 가능 |
| 통계 조회는 주로 월 단위로 이루어짐 | Range 파티셔닝 | 월별 파티션 구성으로 효율적 스캔 |
| 서비스 지역/국가가 다름 | 지역 기준 샤딩 | 법적 요구 대응 + 지리적 거리 단축 |
| 데이터 정합성보다 트래픽이 우선임 | 샤딩 | 성능 확보가 우선, eventually consistent 구조 가능 |

---

## **정리: 파티셔닝·샤딩 설계 체크리스트**

1. **파티션 키가 쿼리에 포함되는지** 확인함
2. 파티션별 데이터 양이 균등하게 나뉘는지 **데이터 분포**를 먼저 파악함
3. 샤딩 전에는 **Join이 필요한 테이블 묶음**을 먼저 정의함
4. 샤딩 이후에는 **샤드 라우팅 로직 또는 미들웨어** 구성이 필요함
5. 샤드 수 증설이 필요할 경우를 대비해 **Hash 대신 Range/Consistent Hash 기반도 고려함**

## 10. **CQRS·Outbox 설계**

### **CQRS란?**

![https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/modernization-data-persistence/cqrs-pattern.html](attachment:7809280b-aca0-4aa1-98a3-a330ecf6e949:cqrs.png)

https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/modernization-data-persistence/cqrs-pattern.html

- **Command Query Responsibility Segregation**
- 한마디로 **쓰기(명령)와 읽기(조회)의 책임을 분리**하는 아키텍처 패턴임
- 전통적인 CRUD 모델은 같은 DB 테이블을 읽고 쓰며 로직을 구성함.
    
    CQRS는 **쓰기 모델과 읽기 모델을 따로 설계**함으로써 성능, 구조, 확장성 측면에서 유리함
    
- 쓰기 모델은 정합성을, 읽기 모델은 성능을 중심으로 설계함

| **구분** | **전통 모델** | **CQRS** |
| --- | --- | --- |
| 데이터 접근 방식 | 동일 모델로 읽기/쓰기 처리 | 명령(Command)과 조회(Query) 모델 분리 |
| 장점 | 구현이 단순함 | 확장성, 성능, 도메인 분리, CQ·EOL 지연 최소화 |
| 단점 | 확장성과 복잡성에 한계 있음 | 구현 난이도, eventual consistency 관리 필요 |

### **CQRS 패턴이 유용한 상황**

- 읽기 트래픽이 **쓰기보다 압도적으로 많은 서비스**
- 복잡한 조회 조건 때문에 **JOIN이 많은 API**
- 각 채널(Web, App, Admin 등)의 화면이 다르면서, 같은 데이터를 다른 방식으로 보여줘야 하는 경우
- 데이터를 저장한 후 **바로 화면에 보여줘야 하는 UX 요구**가 있는 경우

### **실전 예시**

- 상품 등록은 products 테이블에 저장
- 조회는 products_read_model 테이블에서 JOIN 없이 단일 SELECT로 처리

```
-- Command
INSERT INTO products (...) VALUES (...);

-- Query
SELECT * FROM products_read_model WHERE category_id = 123 AND is_active = TRUE;
```

### **Outbox 패턴이란?**

- 분산 시스템에서 **이벤트 발행 시 정합성을 보장**하기 위한 설계임
- DB에 쓰기와 동시에 메시지 큐에 이벤트를 발행하면, 중간에 실패할 경우 **데이터는 저장됐는데 이벤트는 날아가지 않는 문제**가 발생할 수 있음
- 이를 방지하기 위해, **이벤트 발행 요청을 DB 안에 먼저 적재**한 후, 별도 프로세스가 이를 읽어 큐에 전송함
- https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/cloud-design-patterns/transactional-outbox.html

### **Outbox 기본 흐름**

1. 애플리케이션이 DB에 쓰기를 수행하면서 outbox_event 테이블에도 함께 INSERT
2. 트랜잭션이 커밋되면 이벤트는 DB에 안전하게 저장됨
3. 별도 프로세스가 outbox_event 테이블을 폴링하면서 메시지 브로커(Kafka 등)에 전송함
4. 전송이 성공하면 해당 이벤트는 삭제하거나 전송 완료로 마킹함

```
BEGIN;

INSERT INTO orders (...) VALUES (...);
INSERT INTO outbox_event (type, payload, status) VALUES ('order_created', '{...}', 'PENDING');

COMMIT;
```

### **Outbox + CQRS 통합 구조**

- Outbox는 **쓰기 트랜잭션의 신뢰성을 확보**해 주고,
- CQRS는 **읽기 트래픽 분산과 성능 최적화**를 가능하게 해 줌
- 이 둘을 함께 사용하면 **고성능이면서 정합성도 확보된 아키텍처**를 만들 수 있음

### **흐름 정리**

1. 도메인 객체 저장 (쓰기 모델)
2. 이벤트를 Outbox 테이블에 기록
3. Outbox 컨슈머가 이벤트를 MQ로 발행
4. MQ 소비자가 읽기 모델 테이블을 갱신
5. 읽기 요청은 별도 Read Model에서 처리

### **실무에서의 주의점**

| **항목** | **설명** |
| --- | --- |
| Outbox 테이블 설계 | 메시지 재전송을 위해 상태(PENDING/SENT/FAILED)와 타임스탬프 포함 필요 |
| 장애 복구 | MQ 장애 시에도 Outbox 테이블이 있기 때문에 복구 후 재시도 가능 |
| 읽기 모델 갱신 지연 | Read Model은 즉시 갱신되지 않음 → 프론트 UX 설계에서 고려 필요 |
| 테스트 전략 | Write 모델, Read 모델, 이벤트 처리 각각을 독립적으로 검증해야 함 |

## **정리: CQRS & Outbox 설계 포인트**

1. CQRS는 **읽기/쓰기 책임 분리를 통해 성능과 유지보수성을 개선**함
2. Outbox는 **분산 시스템에서의 정합성 보장을 위한 안전 장치**임
3. 둘을 조합하면 **확장성과 신뢰성을 동시에 만족하는 구조**가 됨
4. 단, 구현 복잡도와 **eventual consistency**에 대한 이해가 전제되어야 함
5. 실시간 UX 요구가 있다면 **프론트 캐싱 또는 응답 포함 전략**도 함께 고려해야 함

## 11. **데이터 거버넌스 + 수명 주기 & GDPR**

### **실무에서 겪는 운영 이슈**

- 서비스가 돌아가는 중에 테이블에 인덱스를 추가하거나 컬럼을 수정해야 하는 경우가 많음
- 사용자 정보, 결제 내역처럼 민감한 데이터를 어떻게 저장하고 암호화할지 정해야 함
- 컬럼 이름이나 타입이 일관되지 않아, 협업이나 리포트 생성 시 혼란이 생기는 경우가 잦음
- 법적 규제(GDPR, ISMS 등)에 맞춰 **데이터 수명 주기나 삭제 방식**을 미리 설계하지 않으면 대응이 늦어짐

→ 이 모든 항목은 “성능”과 “정합성”만으로는 설명할 수 없는 **운영, 보안, 거버넌스 설계의 영역**임

---

### **1. 무중단 스키마 변경: Online Schema Change**

### **왜 필요한가?**

- 실무에서는 아래와 같은 일이 자주 생김:

```
- 운영 중인 주문 테이블에 인덱스를 추가해야 함
- 컬럼 타입을 바꾸고 싶음 (예: VARCHAR → TEXT)
- NOT NULL 제약을 추가하고 싶음
```

→ 하지만 MySQL이나 MariaDB의 ALTER TABLE은 내부적으로 **전체 테이블을 다시 쓰는 작업(테이블 rebuild)**을 실행함

→ 수백만 건 이상인 테이블에서는 몇 초~수십 초 동안 **락이 걸리거나 디스크 IO가 폭증**함

- 운영 중에는 `ALTER TABLE` 한 줄로 서비스 장애가 발생할 수 있음

### **대표적인 OSC 도구**

| **도구** | **설명** |
| --- | --- |
| pt-online-schema-change | Percona Toolkit에서 제공. 트리거 기반 복제 방식 |
| gh-ost | GitHub에서 개발. Binlog 기반 변경 방식으로 락 최소화 |
| oak-online-alter | Facebook 도구. 안정성 높지만 도입 난이도 있음 |

### **OSC 방식 요약**

1. 신규 테이블 생성 (table_ghost)
2. 트리거로 기존 테이블의 변경 내용을 복제
3. 백그라운드에서 신규 테이블에 데이터 복사
4. 완료되면 RENAME TABLE로 원자적으로 교체

### **사용 팁**

- 쓰기 트래픽 많은 테이블일수록 OSC 도구 사용은 필수임
- OSC 수행 중에는 **테이블에 PK 또는 Unique 인덱스가 반드시 있어야 함**
- 장애 방지를 위해 **실서비스와 동일한 테스트 환경에서 Dry-run을 먼저 수행**해야 함

---

### **2. 보안 설계 포인트**

### **민감 정보 암호화**

| **항목** | **암호화 방식** | **주의사항** |
| --- | --- | --- |
| 주민번호, 카드번호 | AES-256 같은 대칭키 암호화 | 키 관리 체계 필요 |
| 로그인 비밀번호 | 단방향 해시 (bcrypt, argon2 등) | salting 필수 |
| 이메일, 전화번호 | 마스킹 처리 | 데이터 가공된 상태로 노출 |
- 암호화는 **“저장” 기준**으로 판단해야 함 (전송 시 암호화는 TLS로 처리됨)
- 키 관리에는 AWS KMS, HashiCorp Vault 같은 도구를 고려함

### **최소 권한 원칙**

- DB 사용자 계정은 목적별로 분리해야 함

| **계정** | **권한** |
| --- | --- |
| API 서버 | SELECT, INSERT, UPDATE, DELETE |
| 배치 서버 | 추가로 DDL 권한 허용 |
| BI/분석 도구 | SELECT만 허용 |
| DBA 전용 | 전체 권한, 실시간 모니터링 포함 |

---

### **3. 데이터 거버넌스 체크리스트**

### **스키마 명명 규칙**

| **항목** | **가이드** |
| --- | --- |
| 테이블명 | snake_case, 단수형 (user, order_item) |
| 컬럼명 | 의미가 명확한 이름 사용 (created_at, status_code) |
| FK 명 | fk_{자식}_{부모} 형식 권장 |
| 인덱스명 | idx_{테이블}_{컬럼} 패턴 사용 |

→ 초기에 가이드라인이 없으면 **수십 개 테이블마다 컬럼명이 제각각**이 되기 쉬움

### **데이터 수명 주기 설계**

- GDPR, ISMS-P 등에서는 **개인정보 보유 기간 및 삭제 방식**에 대한 기준이 요구됨

| **항목** | **설계 예시** |
| --- | --- |
| 탈퇴 회원 데이터 | deleted_at으로 소프트 삭제 후 30일 후 물리 삭제 |
| 주문 로그 | 1년 이상 경과 시 아카이빙 테이블로 이관 |
| 개인정보 열람 이력 | 3년 보존 후 자동 삭제 스케줄링 |

→ 주기적 배치 또는 TTL 기반 삭제 정책을 사전에 정의해둬야 함

### **데이터 접근 통제**

- 쿼리 로그 감사를 위한 시스템 도입 고려 (pgAudit, MySQL Audit Plugin)
- 운영 DB에는 BI 도구, 분석 쿼리 접근을 최소화해야 함
- 대용량 분석은 별도 복제본(분석 전용 DB)으로 분리해서 처리하는 것이 일반적임

---

## **정리: 운영·보안·거버넌스 설계 핵심 포인트**

1. **스키마 변경은 Online 방식으로 수행**해 무중단 운영을 확보함
2. **암호화와 키 관리**, **접근 권한 분리**는 실무 보안의 최소 조건임
3. **명명 규칙과 수명 주기 설계**는 팀 협업과 규제 대응의 핵심 기반임
4. 초기에 무시하면 나중에 **리포트, 심사, 데이터 마이그레이션**에서 큰 비용으로 되돌아옴
5. 거버넌스 설계는 **기능 설계만큼 중요하며**, 반드시 문서화되어 팀에 공유되어야 함

## 11. 요약정리

### **📌 요약 정리**

### **1. 데이터 모델링 핵심**

- 정규화는 **중복 제거와 무결성 확보**를 위한 기본 설계 원칙임
- 반정규화는 **성능과 편의성 우선 상황에서 선택적으로 도입**함
- Surrogate Key(auto_increment, UUID 등)는 **변경 가능성이 낮은 식별자**로 실무에서 선호됨
- 외래키(FK), UNIQUE, CHECK, NOT NULL 등 제약조건을 조합해 **데이터 정확성과 신뢰성을 확보**함

### **2. 락과 동시성 처리 전략**

- 격리 수준은 **정합성과 동시성 사이의 균형**을 조절하는 장치임
- Gap Lock, 데드락 등은 **인덱스 구조와 락 순서**로 충분히 예방 가능함
- **REPEATABLE READ**는 MySQL 기본값이며 대부분의 비즈니스 로직에 적합함

### **3. 인덱스 및 쿼리 설계**

- 인덱스는 **자주 쓰는 WHERE, JOIN, ORDER 컬럼을 기준으로 설계**함
- 복합 인덱스는 **왼쪽부터 순차 접근이 가능**하므로 사용 순서가 중요함
- covering index를 활용하면 **테이블 접근 없이 쿼리를 처리할 수 있음**
- 통계 갱신(ANALYZE)은 **최적 실행 계획을 위한 필수 절차**임

### **4. 읽기 스케일아웃 및 복제 지연**

- 리플리카는 **읽기 트래픽 분산**을 위해 유용하지만, **쓰기 직후 읽기**에서는 반드시 Master를 사용해야 함
- 복제 지연 모니터링 및 Master fallback 정책을 마련해둬야 함
- QA나 테스트 환경에서 **복제 지연에 따른 오류가 자주 발생함** → 코드 레벨 분기가 필요함

### **5. 파티셔닝과 샤딩**

- 파티셔닝은 **단일 테이블을 내부적으로 분할**해 성능을 확보하는 구조
- 샤딩은 **DB 자체를 수평 분할**해 트래픽과 데이터 양을 분산하는 구조
- 샤딩 키 선정이 가장 중요하며, **Cross-Shard Join이 불가능하다는 제약**을 감안해야 함

### **6. CQRS와 Outbox**

- CQRS는 **쓰기와 읽기를 분리**해 각각의 목적에 맞게 최적화할 수 있는 구조
- Outbox는 **DB 트랜잭션과 이벤트 발행 사이의 정합성 보장**을 위한 패턴
- 둘을 조합하면 **확장성과 신뢰성을 동시에 확보할 수 있음**

### **7. 운영·보안·거버넌스**

- Online Schema Change(gh-ost 등)를 통해 **무중단 DDL 수행이 가능함**
- 암호화는 민감도에 따라 **대칭키, 단방향 해시, 마스킹 방식**을 구분해 적용함
- 명명 규칙, 접근 권한 분리, 데이터 수명 주기 관리는 **협업과 감사 대응의 기본 기반**임

### **8. 실무지표**

- DB 설계가 아무리 좋아도, 결국 실무에서는 **“이 설계가 실제로 얼마나 빠르고 안정적인가”**가 중요
- 그래서 우리는 성능 지표(P95, P99)와 같은 **운영 지표 관점의 사고**도 함께 익혀야 함
- P50 / P95 / P99 / P99.9 지표는 실제로 사용자들이 얼마나 빠르게 응답을 받는지를 보여주는 지표이며,
SLO/SLI 기준 수립의 핵심
    
    
    | **지표** | **의미** |
    | --- | --- |
    | P50 | 평균적인 사용자 응답 시간 (Median) |
    | P95 | 95% 사용자가 이 시간보다 빠르게 응답받음 |
    | P99 | 상위 1% 사용자 응답 시간 |
    | P99.9 | 극소수 사용자, 아주 느린 응답도 포함 |
- 이런 지표는 단순한 쿼리 속도 이상으로, **DB 설계 → 인덱스 → 락 → 동시성 → 캐시**까지 설계 전체가 영향을 미침
    
    ![image.png](attachment:874590e5-c597-4019-bf01-cf322e0579f0:image.png)
    

## 12. 과제

<aside>
🚢

지난 강의에서 아키텍처의 큰 그림을 잡았다면,
이번 과제는 **“DB를 어떻게 설계하고, 트랜잭션을 어디까지 끊어야 하며, 정합성은 어떻게 보장할 것인가?”**를 집중적으로 다룹니다.

</aside>

### `필수 과제 **- Integration`**

- Infrastructure Layer 작성 (**“외부 세계와 연결된 모든 것”을 담당하는 계층**)
    - 예시
        - **Spring(Java) 프로젝트 예시 -  infrastructure는 구현체 (Adapter)**
            
            ```java
            📂 com.example.orderapp
             ┣ 📂 domain
             ┃ ┣ 📂 order
             ┃ ┃ ┣ 📄 Order.java
             ┃ ┃ ┣ 📄 OrderRepository.java     <-- Domain Layer
             ┃ ┣ 📂 product
             ┃ ┃ ┣ 📄 Product.java
             ┃ ┃ ┣ 📄 ProductRepository.java   <-- Domain Layer
             ┣ 📂 application
             ┃ ┣ 📂 order
             ┃ ┃ ┣ 📄 OrderService.java        <-- Use Case
             ┃ ┃ ┣ 📄 OrderCommand.java
             ┣ 📂 infrastructure
             ┃ ┣ 📂 persistence
             ┃ ┃ ┣ 📂 order
             ┃ ┃ ┃ ┣ 📄 OrderRepositoryImpl.java    <-- 실제 JPA 구현체
             ┃ ┃ ┣ 📂 product
             ┃ ┃ ┃ ┣ 📄 ProductRepositoryImpl.java
             ┃ ┣ 📂 external
             ┃ ┃ ┣ 📄 MessageQueueProducer.java     <-- MQ, 외부 연동
             ┃ ┃ ┣ 📄 NaverApiClient.java
             ┃ ┣ 📂 configuration
             ┃ ┃ ┣ 📄 RedisConfig.java
             ┃ ┃ ┣ 📄 JpaConfig.java
             ┣ 📂 api
             ┃ ┣ 📄 OrderController.java           <-- Controller Layer
            ```
            
        - **NestJS(TypeScript) 프로젝트 예시 - infrastructure: Adapter (DB, MQ, 외부 API 등)**
            
            ```tsx
            📦 src
             ┣ 📂 domain
             ┃ ┣ 📂 order
             ┃ ┃ ┣ 📄 order.entity.ts
             ┃ ┃ ┣ 📄 order.repository.ts           <-- 인터페이스
             ┃ ┣ 📂 product
             ┃ ┃ ┣ 📄 product.entity.ts
             ┃ ┃ ┣ 📄 product.repository.ts
             ┣ 📂 application
             ┃ ┣ 📂 order
             ┃ ┃ ┣ 📄 order.service.ts             <-- 유즈케이스
             ┃ ┃ ┣ 📄 dto/
             ┣ 📂 infrastructure
             ┃ ┣ 📂 persistence
             ┃ ┃ ┣ 📂 order
             ┃ ┃ ┃ ┣ 📄 order.repository.impl.ts   <-- 실제 구현체 (TypeORM 등)
             ┃ ┃ ┣ 📂 product
             ┃ ┃ ┃ ┣ 📄 product.repository.impl.ts
             ┃ ┣ 📂 external
             ┃ ┃ ┣ 📄 message-queue.producer.ts
             ┃ ┃ ┣ 📄 naver-api.client.ts
             ┃ ┣ 📂 configuration
             ┃ ┃ ┣ 📄 redis.config.ts
             ┃ ┃ ┣ 📄 typeorm.config.ts
             ┣ 📂 interfaces
             ┃ ┣ 📂 controllers
             ┃ ┃ ┣ 📄 order.controller.ts         <-- API 계층
             ┃ ┣ 📂 dto
             ┃ ┃ ┣ 📄 create-order.dto.ts
            ```
            
- 기능별 통합 테스트 작성
    - Testcontainers(Optional) 또는 테스트 전용 DB로 테스트 가능하도록 구성
- **e-커머스 상품 주문 서비스**
    
    **1. Infrastructure Layer 구현**
    
    - UserBalanceRepository, ProductRepository, OrderRepository, CouponRepository 등 도메인 기반 리포지토리 구현
    - 외부 메시지 전송 기능은 **Kafka 대신 MockMessageProducer 또는 Outbox 테이블 방식으로 구현**
    - 외부 API/Fake Producer 등은 의존성 주입 형태로 설계하여 테스트 가능하도록 구성
        - 예: 주문이 완료되었을 때
        → 데이터 플랫폼(외부 시스템)에 주문 정보를 실시간 전송해야 한다
    
    **2. 기능별 통합 테스트 작성**
    
    - 충전 API → 주문 API까지 잔액 변경 테스트 포함
    - 상품 주문 & 결제 흐름 전체 통합 테스트
        - 주문 → 재고 차감 → 잔액 차감 → 주문 저장 → 외부 전송 Mock 검증
    - 외부 메시지 전송 실패 시 fallback 처리 검증 (e.g. Outbox 저장 여부 확인)
    - **결제 API는 idempotency_key 사용** → 중복 요청 테스트 포함
    - 쿠폰 발급 경쟁 조건 테스트: 동시에 요청 시 한 명만 성공
- **콘서트 예약 서비스**
    
    **1. Infrastructure Layer 구현**
    
    - ReservationTokenRepository, SeatReservationRepository, UserBalanceRepository, PaymentRepository 등 구현
    - 임시 좌석 배정: **Redis 없이도 상태 컬럼 + 만료 시간 방식으로 구현 가능**
    - 대기열 토큰 관리: Redis 또는 DB 기반으로 구현
    
    **2. 기능별 통합 테스트 작성**
    
    - 유저가 토큰을 발급받고 → 좌석 예약 요청 → 결제 완료까지의 흐름 테스트
    - 만료 시간 도래 후 좌석이 다시 예약 가능한지 확인
    - 다중 유저가 동시에 좌석 요청 시 한 명만 성공하도록 테스트 구성

> `Infrastructure` 는 RDMBS ( MySQL ) 기반으로 작성합니다.
> 

### **`(선택)심화 과제 - DB`**

- 조회가 오래 걸릴 수 있는 기능을 리스트업하고 분석하여, 테이블 재설계 / 인덱스 등 솔루션을 도출하는 내용의 보고서 작성
- 주요 기능별 동시성 테스트 작성

> 이번 과제에서 동시성 테스트는 성공하는 것이 목적이 아니라, 어떤 기능에 대해 동시성 이슈가 예민할지를 미리 리스트업하고 작성하여 Rule 로 가두는 것을 목적으로 합니다.
> 

<aside>
<img src="/icons/light-bulb_red.svg" alt="/icons/light-bulb_red.svg" width="40px" />

**참고 PR 링크**

| 스택 | STEP4 |
| --- | --- |
| Java | https://github.com/BEpaul/hhplus-e-commerce/pull/26 |
| Java | https://github.com/juny0955/hhplus-concert/pull/22 |
| Kotlin | https://github.com/chapakook/kotlin-ecommerce/pull/32 |
| Kotlin | https://github.com/psh10066/hhplus-server-concert/pull/20 |
| TS | https://github.com/psyoongsc/hhplus-ts-server/pull/34 |
| TS | https://github.com/suji6707/nestjs-case-02-ticketing/pull/4 |
</aside>

---

Copyright ⓒ TeamSparta All rights reserved.